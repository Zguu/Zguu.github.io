---
title: " [ì„ í˜•ëŒ€ìˆ˜í•™] positive definite, semi-positive definite"
tags: LinearAlgebra Rank FullRank PositiveDefinite SemiPositiveDefinite
---

# Positive Definite í–‰ë ¬ & Semi positive Definite í–‰ë ¬
## ê³ ìœ ê°’ìœ¼ë¡œ ì •ì˜ë˜ì§€ë§Œ..
***<center>A matrix is positive definite if it's symmetric and all its eigenvalues are positive</center>***
> ì•„ì£¼ ê°„ë‹¨í•œ ì •ì˜ì´ë‹¤. í–‰ë ¬ì´ ëŒ€ì¹­í–‰ë ¬ì´ê³  ê³ ìœ ê°’ë“¤ì´ ëª¨ë‘ ì–‘ìˆ˜ì´ë©´ ëœë‹¤ê³  í•œë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë°”ë¡œ í•œê°€ì§€ ê±±ì •ì´ ìƒê²¨ì•¼ í•œë‹¤.
  ì•„ ê³ ìœ ê°’ ì €ê±° ê·€ì°®ê²Œ ì–¸ì œ ë‹¤ ê³„ì‚°í•˜ì§€?!

ëª¨ë“  eigenvalueë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì€ matrix dimensionì´ ì¦ê°€í•¨ì— ë”°ë¼ ë³µì¡í•´ì§„ë‹¤. ë‹¹ì¥ 2x2 í–‰ë ¬ì—ì„œ ê³ ìœ ê°’ ê³„ì‚°ê³¼ 3x3 í–‰ë ¬ì—ì„œ ê³ ìœ ê°’ ê³„ì‚°ë„ ë³µì¡ë„ê°€ ê½¤ë‚˜ ì°¨ì´ë‚œë‹¤. dimensionì€ 1 ì”©ë§Œ ëŠ˜ì—ˆëŠ”ë°.. ë”°ë¼ì„œ ì¢€ ë” íš¨ìœ¨ì ì´ê³  ëœ ê·€ì°®ì€ ë°©ë²•ì„ ì°¾ì•„ì•¼ í•œë‹¤.<br>
ë‹¤ìŒì˜ ì„±ì§ˆì„ ì‚¬ìš©í•˜ì.
***<center>í–‰ë ¬ì´ ê°–ëŠ” ëª¨ë“  eigenvalueì˜ ë¶€í˜¸ëŠ” í•´ë‹¹ í–‰ë ¬ pivotë“¤ì˜ ë¶€í˜¸ì™€ ê°™ë‹¤.</center>***
> 3x3 í–‰ë ¬ì—ì„œ, pivotì´ 2,-3,3 ìœ¼ë¡œ 2ê°œê°€ ì–‘ìˆ˜, 1ê°œê°€ ìŒìˆ˜ë¼ë©´, ê³ ìœ ê°’ ë˜í•œ 2ê°œëŠ” ì–‘ìˆ˜ì´ê³  1ê°œëŠ” ìŒìˆ˜ë¼ëŠ” ì„±ì§ˆì´ë‹¤. í•´ë‹¹ ì„±ì§ˆì— ëŒ€í•œ ì¦ëª…ì€ (ì–´ë µë‹¤.)

ìœ„ì˜ ì„±ì§ˆì„ ì´ìš©í•˜ë©´ ì²˜ìŒ ì œì‹œëœ positive definite ì •ì˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë°”ê¿€ ìˆ˜ ìˆë‹¤.
***<center>A matrix is positive definite if it's symmetric and all its pivots are positive</center>***
> í•´ë‹¹ ë§¤íŠ¸ë¦­ìŠ¤ê°€ symmetricì´ë©°, ëª¨ë“  pivots valueê°€ ì–‘ìˆ˜ì´ë©´ positive definite matrixë¡œ ë³¸ë‹¤.

ì¦‰, pivotë“¤ì˜ ë¶€í˜¸ë§Œ í™•ì¸í•˜ë©´ ëœë‹¤.

ì•„ë˜ì˜ ê²½ìš°ë¥¼ ë³´ë©´ì„œ pivotì„ í†µí•œ positive definite í™•ì¸ì„ í•´ë³´ì.
<center>$$\begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix}$$</center>
ìœ„ì˜ í–‰ë ¬ì„ Gaussian eliminationì„ í†µí•´ ë³€ê²½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
<center>$$\begin{pmatrix} 1 & 2 \\ 0 & -3 \end{pmatrix}$$</center>
í–‰ë ¬ì˜ ëŒ€ê°ì„ ì— ìˆëŠ” ê°’ë“¤ì€ ê°ê° 1, -3 ì´ë©° í•´ë‹¹ pivot ê°’ë“¤ ì¤‘ 1ê°œëŠ” ì–‘ìˆ˜ì´ë©° 1ê°œëŠ” ìŒìˆ˜ì´ë‹¤. ë”°ë¼ì„œ eigenvalue ë˜í•œ (ìš°ë¦¬ê°€ ê³„ì‚°ì€ ì•„ì§ ì•ˆí•´ë´¤ì§€ë§Œ) 1ê°œëŠ” ì–‘ìˆ˜ì´ê³  1ê°œëŠ” ìŒìˆ˜ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.

## pivot ê³„ì‚°ë„ ì‰½ì§€ê°€ ì•Šì€ë°..?
$\ $kë²ˆì§¸ pivot ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
<center>$$d_k = \frac{det(A_k)}{det(A_{k-1})}$$</center>
ì—¬ê¸°ì—ì„œ $$A_k$$ëŠ” upper left k x k submatrixì— í•´ë‹¹í•œë‹¤. ë‹¤ìŒ ë²”ìœ„ $$1 \le k \le n$$ ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  $k$ì— ëŒ€í•˜ì—¬ ë‹¤ìŒì´ $$det(A_k)$$ ì„±ë¦½í•œë‹¤ë©´ ëª¨ë“  pivot ê°’ë“¤ì€ ì–‘ìˆ˜ì„ì´ í™•ì¸ ë  ê²ƒì´ë‹¤. ë”°ë¼ì„œ ëª¨ë“  submatrix ì˜ determinants ê°’ì´ ì–‘ìˆ˜ì„ì„ í™•ì¸í•˜ë©´ ëœë‹¤. ì•„ë˜ì˜ í–‰ë ¬ì´ positive definiteì¼ì§€ ê³„ì‚°í•´ë³´ì.
<center>$$\begin{pmatrix} 2 & -1 & 0 \\ -1 & 2 & -1 \\ 0 & -1 & 2 \end{pmatrix}$$</center>
<center>$$d_1 = 2$$</center>
<center>$$d_2 = \begin{vmatrix} 2 & -1 \\ -1 & 2 \end{vmatrix} = 3$$</center>
<center>$$d_3 = \begin{vmatrix} 2 & -1 & 0 \\ -1 & 2 & -1 \\ 0 & -1 & 2 \end{vmatrix} = 4$$</center>
$$d_1, d_2, d_3 > 0 $$ ì´ë¯€ë¡œ, positive definite í–‰ë ¬ì„ì´ í™•ì¸ëœë‹¤.

> 2x2 í–‰ë ¬ $$\begin{pmatrix} a & b \\ c & d \end{pmatrix}$$ ì—ì„œ $$determinant = ad\ -\ bc$$ ë¡œ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.<br>
 ë§ˆì°¬ê°€ì§€ë¡œ, 3x3 í–‰ë ¬ $$\begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix}$$ ì—ì„œ $$determinant = a(ei\ -\ fh) - b(di\ -\ fg) + c(dh\ -\ eg)$$ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ì‰½ê²Œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, í–‰ë ¬ ì°¨ì›ìˆ˜ê°€ ì»¤ì§ì— ë”°ë¼ ì´ëŸ¬í•œ ë°©ë²•ë„ ì ì  ë³µì¡í•´ì§„ë‹¤.

## energy-based definition & $$R^TR$$ definition
### energy-based definition of positive definite
$\ $ì¡°ê¸ˆ ë” í–‰ë ¬ìŠ¤ëŸ¬ìš´ ê³„ì‚° ì ‘ê·¼ìœ¼ë¡œ positive definiteë¥¼ ì •ì˜í•´ë³´ì. $$\mathbf{x} \ne 0$$ì¸ $$\mathbf{x}$$ê°€ $A$ì˜ ê³ ìœ ë²¡í„°ë¼ë©´, ì´ ê²½ìš°ì— ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤. $$\mathbf{x}^T\mathbf{Ax} = \lambda \mathbf{x}^T \mathbf{x}$$<br>
$\ $ì—¬ê¸°ì—ì„œ, ë§Œì•½ $$\lambda > 0$$ ì´ë¼ë©´, $$\mathbf{x}^T\mathbf{x} > 0 $$ ì´ë¯€ë¡œ, í•­ìƒ ë‹¤ìŒì´ ì„±ë¦½í•´ì•¼ë§Œ í•œë‹¤. $$\mathbf{x}^T\mathbf{Ax} > 0$$.<br>
$\ $ì¦‰, ë‹¤ìŒê³¼ ê°™ì´ positive definite ë§¤íŠ¸ë¦­ìŠ¤ì— ëŒ€í•œ ì •ì˜ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆë‹¤.
***<center>A matrix is positive definite if $$\mathbf{x}^T\mathbf{Ax} > 0$$ for all vectors $$\mathbf{x}\ \ne 0.$$</center>***
$\ $ë¬¼ë¦¬í•™ì—ì„œ ìƒíƒœ $$\mathbf{x}$$ì— ìˆëŠ” ì‹œìŠ¤í…œì˜ **energy** ëŠ” ë³´í†µ $$\mathbf{x}^T\mathbf{Ax}$$ (ë˜ëŠ”, $$\frac{1}{2}\mathbf{x}^T\mathbf{Ax}$$)ë¡œ ìì£¼ í‘œí˜„ë˜ê¸° ë•Œë¬¸ì— ì´ì™€ ê°™ì´ positive definite ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒì„ ***energy-based definition*** ìœ¼ë¡œ ë¶€ë¥¸ë‹¤. ì´ë¥¼ í™œìš©í•˜ì—¬ positive definite ë§¤íŠ¸ë¦­ìŠ¤ì— ëŒ€í•œ ë˜ë‹¤ë¥¸ ì •ì˜ë¥¼ ìœ ë„í•´ë³¼ ìˆ˜ë„ ìˆë‹¤.<br>
### $$R^TR$$ definition of positive definite
$\ $ êµ¬ì„± columnë“¤ì´ ì„œë¡œ ë…ë¦½ì ì´ë©° ì§ì‚¬ê°í˜• í˜•íƒœì¸ ë§¤íŠ¸ë¦­ìŠ¤ $$R$$ ì´ ìˆë‹¤ê³  í–ˆì„ ë•Œ, $$ A = R^TR $$ ë¡œ ì‘ì„±ë  ìˆ˜ ìˆëŠ” ëª¨ë“  ë§¤íŠ¸ë¦­ìŠ¤ $$A$$ëŠ” positive definite ë§¤íŠ¸ë¦­ìŠ¤ì´ë‹¤. ***$$ A = R^TR $$ ë¥¼ ë§Œì¡±í•˜ëŠ” $A$ëŠ” positive definite ë§¤íŠ¸ë¦­ìŠ¤ì´ë‹¤.*** ë¼ëŠ” ì´ ì •ì˜ëŠ” energy-based ì •ì˜ë¥¼ ì´ìš©í•´ ì‰½ê²Œ ì¦ëª…ë  ìˆ˜ ìˆë‹¤. ì•„ë˜ì˜ ì‹ì„ ë³´ì.
<center>$$\mathbf{x}^T\mathbf{Ax} = \mathbf{x}^T\mathbf{R}^T\mathbf{Rx} = (\mathbf{Rx}^T)(\mathbf{Rx}) = \lVert \mathbf{Rx}\rVert^2$$</center>
$\ $ë§Œì•½ $$R$$ì˜ ì—´ë“¤ì´ linearly independent ì´ê³ , $$\mathbf{x} \ne 0$$ ì´ë¼ë©´, $$\mathbf{Rx} \ne 0$$ ì´ ì„±ë¦½í•˜ë©°, ë”°ë¼ì„œ $$\mathbf{x}^T\mathbf{Ax} > 0$$ ì„ ë§Œì¡±í•œë‹¤. ìµœì¢…ì ì¸ $$\lVert \mathbf{Rx}\rVert^2$$ ê°’ì´ ì–‘ìˆ˜ì´ë¯€ë¡œ, ê²°ê³¼ì ìœ¼ë¡œ $$\mathbf{x}^T\mathbf{Ax} > 0$$ ì„ ë§Œì¡±í•œë‹¤. ë”°ë¼ì„œ ë‹¤ìŒê³¼ ê°™ì´ positive definite ë§¤íŠ¸ë¦­ìŠ¤ì— ëŒ€í•´ ì •ì˜í•  ìˆ˜ ìˆë‹¤.
***<center>A matrix $A$ is positive definite if and only if it can be written as $$A = R^TR$$ for some possibly rectangular matrix $R$ with independent columns</center>***
$\ $ë§ˆì§€ë§‰ìœ¼ë¡œ, í•´ë‹¹ ë§¤íŠ¸ë¦­ìŠ¤ì˜ ëª¨ë“  ê³ ìœ ê°’ì´ ì „ë¶€ ì–‘ìˆ˜ê°€ ì•„ë‹ˆë¼, 0 ì´ìƒì„ ë§Œì¡±í•  ë•Œì—ëŠ”, ***positive definite***ê°€ ì•„ë‹ˆë¼ ***positive semidefinite*** ë¼ê³  ë§í•œë‹¤. ë‹¤ìŒ ë§¤ë¦­ìŠ¤ê°€ ***positive semidefinite*** ë¥¼ ë§Œì¡±í•˜ê¸° ìœ„í•´ì„œëŠ” $b$ì˜ ê°’ì´ ì–´ë–»ê²Œ ë¼ì•¼í•  ì§€ ê³„ì‚°í•´ë³´ì.<br>
<center>$$\begin{pmatrix} 2 & -1 & b \\ -1 & 2 & -1 \\ b & -1 & 2 \end{pmatrix}$$</center>
$\ $ìœ„ ë§¤íŠ¸ë¦­ìŠ¤ì˜ determinantê°€ í•­ìƒ 0 ì´ìƒì´ ë˜ë„ë¡ í•˜ëŠ” $b$ì˜ ê°’ì„ ì°¾ëŠ” ë¬¸ì œì™€ ê°™ë‹¤.<br>
<center>$$d_3 = \begin{vmatrix} 2 & -1 & b \\ -1 & 2 & -1 \\ b & -1 & 2 \end{vmatrix} $$</center>
<center>$$= 2(4-1) - (-1)(-2+b) + b(1-2b)$$</center>
<center>$$= -2b^2 + 2b + 4 \geq 0 $$</center>
<center>$$\Rightarrow b^2 - b -2 \leq 0$$</center>
<center>$$(b-2)(b+1) \leq 0$$</center>
<center>$$\therefore -1 \leq b \leq 2$$</center>

A (real) symmetric matrix has a complete set of orthogonal eigenvectors for which the corresponding eigenvalues are are all real numbers. For non-symmetric matrices this can fail. For example, a rotation in two dimensional space has no eigenvector or eigenvalues in the real numbers, you must pass to a vector space over the complex numbers to find them.

If the matrix is additionally positive definite, then these eigenvalues are all positive real numbers. This fact is much easier than the first, for if ğ‘£ is an eigenvector with unit length, and ğœ† the corresponding eigenvalue, then

ğœ†=ğœ†ğ‘£ğ‘¡ğ‘£=ğ‘£ğ‘¡ğ´ğ‘£>0
where the last equality uses the definition of positive definiteness.

The importance here for intuition is that the eigenvectors and eigenvalues of a linear transformation describe the coordinate system in which the transformation is most easily understood. A linear transformation can be very difficult to understand in a "natural" basis like the standard coordinate system, but each comes with a "preferred" basis of eigenvectors in which the transformation acts as a scaling in all directions. This makes the geometry of the transformation much easier to understand.

For example, the second derivative test for the local extrema of a function ğ‘…2â†’ğ‘… is often given as a series of mysterious conditions involving an entry in the second derivative matrix and some determinants. In fact, these conditions simply encode the following geometric observation:

If the matrix of second derivatives is positive definite, you're at a local minimum.
If the matrix of second derivatives is negative definite, you're at a local maximum.
Otherwise, you are at neither, a saddle point.
You can understand this with the geometric reasoning above in an eigenbasis. The first derivative at a critical point vanishes, so the rates of change of the function here are controlled by the second derivative. Now we can reason geometrically

In the first case there are two eigen-directions, and if you move along either the function increases.
In the second, two eigen-directions, and if you move in either the function decreases.
In the last, there are two eigen-directions, but in one of them the function increases, and in the other it decreases.
Since the eigenvectors span the whole space, any other direction is a linear combination of eigen-directions, so the rates of change in those directions are linear combinations of the rates of change in the eigen directions. So in fact, this holds in all directions (this is more or less what it means for a function defined on a higher dimensional space to be differentiable). Now if you draw a little picture in your head, this makes a lot of sense out of something that is quite mysterious in beginner calculus texts.

This applies directly to one of your bullet points
