---
title: " [베이지안 with Python] 베이지안 Multi-Armed Bandit(MAB)"
tags: Bayesian Python
---

# Multi-Armed Bandits (MAB)
$\ $MAB 문제를 정의하고, 이 문제를 베이지안 관점에서 해결해보자.
> 우리가 $N$ 개의 슬롯머신을 마주하고있다고 가정하자. 각각의 슬롯머신이 보상을 줄 확률은 각기 다르며, 우리는 이 값을 현재 알지 못한다. 한 번에 한개의 슬롯머신을 택하면서, 우리는 어떻게 해야 우리의 보상을 최대화할 지에 대해 고민해야한다.

> 예를 들어, 4개의 슬롯머신이 있고, 각각의 머신이 보상을 줄 확률은 (0.1, 0.3, 0.65, 0.8) 이라고 해보자. 네번째에 해당하는 슬롯머신이 가장 높은 확률로 보상을 준다는 것을 알게되면 우리는 당연히! 네번째 머신만 계속해서 작동시킬 것이다. 결국 이 문제는 최대 확률을 갖는 슬롯머신을 최대한 빠르게 찾는 것이다.

## 어떻게 접근할까?
$\ $해당 문제는 ***online algorithm*** 의 관점에서 바라보아야 하며, 조금 더 구체적으로는 강화학습 알고리즘의 일종이다. 일종이라고 하기 좀 애매한 것이, 사실 MAB가 강화학습의 시조 격이다. ***offline algorithm*** 과는 다르게, 온라인 알고리즘은 계속해서 입력을 차례로 입력받으며, 학습을 계속 진행한다.
> online algorithm : 시작할 때 모든 입력 정보를 갖고 처리하는 것이 아니라, 입력이 차례대로 들어오는 상황에서 처리하는 알고리즘을 말한다. 반대로, offline 알고리즘은 우리가 알고리즘을 처리할 때 모든 데이터를 다 갖고 있어야만 한다.

베이지안 접근으로 각각의 Bandits(슬롯머신)
