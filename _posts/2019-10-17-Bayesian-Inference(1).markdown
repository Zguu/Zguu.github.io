---
title: " [베이지안 추론] 사전확률? 사후확률? "
tags: Bayesian Statistics Inference Prior Posterior Likelihood Evidence
categories : [BayesStatistics]
---

## Prior(사전확률)과 Posterior(사후확률)
베이즈 규칙에서 Prior(사전확률)과 Posterior(사후확률)에 대한 이해를 돕기 위해 간단한 동전의 경우를 살펴보자. 흠집이 없이 아주 대칭의 모양을 지닌('fair한') 동전은 그 동전을 던졌을 때, 50%의 확률로 앞면이, 50%의 확률로 뒷면이 나오게 될 것이다. 하지만 실제 경우에서 동전의 변형 또는 다른 다양한 이유로, 우리는 이 50%, 50% 확률이 때때로 왜곡된다고 생각할 수도 있다.
예를 들어, 동전 모양이 꽤나 왜곡돼서, 우리는 현재 이 동전을 던지면 20%의 확률로 앞면이, 80%의 확률로 뒷면이 나올 것이라고 믿고 있다. 이렇게 우리가 실제로 동전을 던져보기전에 갖고 있는 사건(event)에 대한 믿음을 사전확률이라고 하자.<br>
만약, 실제로 동전을 10번 던진 후 관찰 결과, 앞면이 2번, 뒷면이 8번 나왔다면, 우리는 우리가 이 사건 전에 지니고 있던 확률, 즉, Prior(사전확률)에 대한 믿음을 더욱 확고히 하게 된다.<br>
우리가 학교나 책을 통해 이 Prior와 Posterior에 대한 개념을 처음 접할 때, 보통 시간 순서로 (이전에 일어난 확률) 과 (이후에 일어난 확률)로 받아들인다. 하지만 이렇게 이해하는 것보다는, 특정한 데이터 셋(우리가 앞에서 본 동전을 던져 실제로 나온 비율의 값들)을 배제했을 때 우리의 믿음을 Prior, 포함시켰을 때 우리의 믿음을 Posterior로 이해하는 것이 낫다.<br>
데이터를 활용한 추론의 목표에는 크게 세 가지 종류가 있다.
<center><br>
- Estimation of parameter values<br>
- Prediction of data values<br>
- Model comparison<br>
</center>

## Bayes' Rule accounting for Data
$$p(\theta|D) = posterior$$ 사후확률<br>
$$p(D|\theta) = likelihood$$ 가능도<br>
$$p(\theta) = prior$$ 사전확률<br>
$$p(D) = evidence$$ 관측확률<br>
사전확률 = 데이터가 주어지지 않았을 때, theta 값의 분포 함수<br>
where the evidence is $$p(D) = \int d\theta p(D|\theta)p(\theta) $$<br>
Bayes' Rule : $$p(\theta|D) = p(D|\theta)p(\theta)/p(D)$$

## An example with coin flipping
동전을 던지는 예시에서 사전확률과 가능도, 사후확률의 분포에 대하여 아래 그래프를 보며 이해해보자. 우리는 현재 이 동전이 fair하다고 생각하므로, 우리의 사전 확률 분포는 아래의 맨 위 그래프 분포와 같다. 해당 사전분포를 가진 상태에서, 앞면이 3회, 뒷면이 9회 나올 확률을 계산해보면 해당 식은 $$p(D|\theta) = {\theta}^3(1-\theta)^9$$ 의 형태를 띄게 된다. 따라서 사전 확률 분포에서 $\theta$ 값이 0.25일 때 가능도는 가장 높고, 0.5일 때가 그 뒤를 따르며, 0.75일 때 가능도는 사실상 0에 가깝게 된다. 이렇게 가능도를 최대화시키는 $\theta$ 값을 maximal likelihood estimate of  $$\theta$$라고 부르자.<br>
이후에, evidence에 해당하는 $p(D)$에 대한 값을 계산해보자. 해당 값은 $$p(D) = \sum p(D|\theta)p(\theta)$$ 를 통해 계산한다. 이 계산된 값은 사후확률 분포의 normalizer로 사용될 것이므로, 해당 plot에 표기해준다.

!['Imgur'](https://imgur.com/Kmd35Rn.png)

위의 figure에서 사전확률, 우도를 활용해 사후확률이 업데이트 된 것을 좀 더 살펴보자. 사후확률 분포는 사전확률과 우도의 곱에 비례한다. 하지만 우도 함수에서 $\theta = 0.5 $ 에서의 값이 너무 작아, 사후분포에서 해당 값이 매우 움츠려든 것을 볼 수 있다. 우리가 기존에 믿던 사전확률 (이 동전은 평평할 거야!!) 은 현재의 사후확률(이 동전이 평평할리 없다...)로 업데이트 됐다. 이렇게 베이지안 확률 계산은 정확하게 우리의 믿음이 어떻게 변하는 지에 대해 계산할 수 있게 해준다.

## Estimation of parameter values
파라미터 값들에 대한 추정은, 우리가 각각의 가능한 파라미터 값들에 대하여 어느 정도 까지 믿고 있는 가에 대한 정도를 결정하는 것을 지칭한다. 파라미터 값 $\theta$에 대한 사후 분포가 해당 값들에 대한 우리의 추정이라고 볼 수 있다.사후분포가 특정 $\theta$에 매우 좁게 분포 된 경우 우리는 꽤나 해당 $\theta$에 대하여 확신 할 수 있는 반면, 만약 사후 분포가 매우 넓게 큰 범위에 걸쳐있다면, 우리는 $\theta$에 대한 높은 불확실성을 갖게 된다.

## Prediction of data values
우리의 현재 믿음을 사용하여, 우리는 미래 값들의 확률을 예측하길 원한다. 추후에 나타날 수도 있는 표기적 혼란을 피하기 위해 이 데이터 값을 $y$로 설정하자. 예측되는 데이터 값 $y$는 가능한 모든 파라미터 값($\theta$)들에 대하여 단순 평균을 냄으로써 진행된다. :<br>
<center> $$p(y) = \int d\theta p(y|\theta)p(\theta) $$ </center><br>
이 값은 잘 들여다보면 정확하게 evidence에 해당한다.<br>
예를 들어서, 위의 Figure 최상단 그래프의 사전확률을 봐보자. 해당 믿음들에 관해 동전을 던질 때 H(head)를 얻게 될 확률 예측은 다음과 같다.

!['Imgur2'](https://imgur.com/utLTyYj.png)

현재 모델의 믿음이 주어졌을 때, 각각의 가능한 데이터 수치의 확률들이 예측 값임에 주목해야한다.
## Model Comparison
지금까지 봐왔던 베이즈 공식은, 모델의 evidence가 사후 확률에 포함 돼있다는 것을 보여준다. 우리가 모델을 어느 정도 믿을 것인가를 평가할 때, 모델의 복잡도가 자동적으로 고려된다는 것이 베이지안 모델 비교의 좋은 점 중 하나이다.이것은 예시와 함께 잘 설명될 수 있다. 우리가 앞에서 다뤘던 동전 던지기 예시를 상기해보자. 해당 예시는 아래 figure의 왼쪽에서 다시 볼 수 있다. 이 예시에서, $\theta$ 값은 오직 세 개의 값만을 가질 수 있었다. 이 제약이 해당 모델을 다소 심플하게 만들어줬었다. 하지만 우리는 추가적으로 더욱 많은 가능한 $\theta$ 값들을 다룰 수 있는 복잡한 모델에 대해서도 생각해야 한다. 해당 모델은 아래 figure의 오른쪽에 위치해 있다. 총 63개의 $\theta$가 가능한 값으로 보여진다. 애매한 데이터 셋들도 조금 더 세밀하게 fit할 수 있는 기회가 생기게 됐다! 왼쪽과 오른쪽의 $\theta$ 갯수 차이에 따른 그래프들이, 왼쪽 $y$값들의 scale 차이가 크다. 이 부분에 대해서는 잠시 생각해보면 알 수 있다.

!['Imgur3'](https://imgur.com/LxmxPaj.png)

위의 simple model(왼쪽 모델) 과 complex model(오른쪽 모델)의 비교를 해보자. 12번의 시도 중 3번 H가 출현하였다. 총 25%의 확률로 H가 나오게 됐는데, 이 경우 evidence 값은 simple model이 0.000416으로 complex model의 0.000392보다 크다. 이 경우 simple model이 더욱 경쟁력있다고 생각할 수 있다. 하지만, 다른 경우에는 complex model이 더욱 경쟁력을 보여주기도 한다. 만약 실제 관측된 데이터가 1개의 head, 11개의 tail을 보여주는 경우를 생각해 보자. simple model의 경우는 어떠한 $\theta$값도 이 결과에 가깝지 않다. 하지만, complex model의 경우 관측된 비율 (1/11) 주변에 몇몇 $\theta$값이 존재한다. (비록 매우 낮은 값들이지만..) Figure 4.3 (아래의 figure)는 이러한 경우에 simple model이 complex model에 비해 더 낮은 evidence를 나타낸다는 것을 보여준다.

!['Imgur4'](https://imgur.com/bnrmlka.png)

모델에 대한 evidence ($$p(D|M)$$)은 해당 모델에 대한 절대적인 의미있음의 크기는 아니다. evidence 값은 관측된 데이터 $D$에서 두 모델간의 상대적 evidence 값인 $$p(D|M1)/p(D|M2)$$, 베이즈 factor, 의 맥락에서만 오로지 가장 의미있다고 할 수 있다. winner 모델은 두 모델의 비교에서만 더욱 우위를 나타낼 뿐이지 최선의 모델이라고 볼 수 있으며, 단지 상대 모델에 비해 덜 나쁘다는 의미로 받아들이는 것이 좋다. 추후에 우리는 다양한 winning 모델들을 어떻게 평가할지 다양한 방면에서 살펴볼 것이다.
## Why Bayesian inference can be difficult
베이지안 추론에서의 모든 세 가지 목표들은 Bayes' 공식의 분모인 evidence를 포함하는데, 이것은 일반적으로 쉽지 않은 적분 계산을 해야함을 의미한다. 이러한 어려움에서 벗어날 수 있는 몇 가지 방법들이 존재한다. 전통적인 방법은 prior function과 conjugate한 likelihood function을 사용하는 것이다. likelihood function과 conjugate한 prior function은 단순하게 posterior 함수가 prior와 같은 형태로 나오는 것을 가능하게 한다. 즉, 수학적으로 작동이 잘 된다. 만약 이 방법이 작동하지 않는다면, 수학적으로 working하기 쉬운 다른 실제와 비슷한 함수에 근사(approximate)하는 방법이 있다. 그리고 특정 조건에섯 해당 근사 함수가 합리적이라는 것을 보여주면 될 것이다. 그러나 이 방법도 여전히 pure하고, 분석적으로는 수학적 방법이다. 또 다른 방법은 numerical하게 적분을 근사하는 방법이다. 파라미터 공간이 작을 때, 이것은 수많은 grid points들로 덮어질 수 있다. 그리고 적분은 해당 grid들에 대한 모든 값들을 모두 더함으로써 계산 될 수 있다. 그러나, 파라미터 공간이 점점 커질 수록, 너무 많은 grid points들이 생겨남녀, 이 방법도 더 이상 쓸 수 없게 된다.<br>
이러한 이유로, random sampling 방법론이라는 접근법이 개발 됐으며, Markov Chain Monte Carlo(MCMC)라고 불려지기도 하는 이 방법론은 numerical하게 확률 분포를 큰 파라미터 공간에서도 근사하는 것을 도와준다. 베이지안 통계 방법론이 실질적 효용을 얻게 된 것은 MCMC 방법론의 발전 덕분이었다. 이 책의 나머지 파트들은 다양한 이 방법론들에 대하여 구체적으로 다룰 것이다. 복잡한 상황에서 까지의 적용을 위해서 우리는 궁극적으로 MCMC 방법론들에 대하여 집중할 것이다. 베이지안 추론의 또 다른 잠재적인 어려움은 합리적인 prior를 결정하는 것이다. 모든 가능한 파라미터 값들 또는 경쟁하는 다른 모델들과 대조해서, 어떠한 믿음의 분포로 우리는 이 추론을 시작할 것인가? 라는 이 질문은 꽤나 당황스럽지만, 실전에서 이것은 전형적으로 직관적인 방법으로 다뤄진다. 우리가 챕터 11에서 더욱 다루겠지만, explicit prior와 함께 추론을 시작하는 것이 실제로 이익이 많으며 합리적이다.
## Holmesian deduction
likelihood $$p(D|{\theta}_i)=0$$ 가 성립한다면, $$p({\theta}_i)>0$$임에 상관없이, $$p({\theta}_j/D)$$는 항상 0 일 수 밖에 없다. Holmes'의 deduction 뒤에 있는 직관은 명료하다 : 우리가 어떤 가능성에 대한 믿음을 줄일 수록, 우리는 필연적으로 남은 확률들에 대한 믿음을 늘릴 수 밖에 없다. 그러므로 Holmesian deduction에 따르면, 데이터가 몇몇 덜 믿을 만한 옵션을 만들면 만들수록, 우리는 다른 옵션들에 대한 믿음을 늘린다.
