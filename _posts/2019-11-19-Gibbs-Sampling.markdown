---
title: " [베이지안 추론] Gibbs Sampling(1)"
tags: Study Bayesian Algorithm Metropolis Probability Gibbs Sampling
---
# Inferring Two Binomial proportions via Gibbs sampling
$\ $이번 챕터는 두 개의 독립적인 이항 비율들에 대한 추론을 어떻게 하는 지에 대해 다룬다. 예를 들어, 우리가 두개의 동전을 갖고 있고 얼마나 그들의 편향도(biases)들이 다른지에 대해 결정하길 원한다고 가정해보자. 이 문제는 각각의 비율에 대한 것이 아니라, 두개의 비율 사이의 관계에 관한 문제이다. <br>
$\ $이 문제에 대해 현재 챕터에서 다루는 이유는, 첫째로, 이 주제는 비율에 관한 추론을 다루는 것이며 이전 챕터들에서 다룬 single proportions에 대한 추론의 연장선이다. 두번째로, 다음 챕터들에서 다룰 hierarchical 모델들에 대한 이해를 돕기 위해서이다. <br>
$\ $이 챕터에서 우리는 깁스 샘플링에 대한 개념을 배울 것이다. 이전 챕터에서 깁스 샘플링이 BUGS에 포함된 개념이라는 것만 배웠다. 깁스 샘플링에서는, 일반적인 Metropolis 알고리즘과는 달리, 제안된 jump 움직임이 한 번에 오직 한개의 파라미터에만 영향을 끼치며 이 제안은 절대로 거부당하지 않는다. 깁스 샘플링 방법론이 항상 작동하는 것은 아니지만, 작동하는 경우에는 굉장히 효율적인 알고리즘에 대해 알게 될 것이다.<br>
$\ $실제 예를 들어보면, 우리가 어떤 병으로 고통받는 100명의 인구 샘플을 갖고 있다고 해보자. 우리는 그들 중 절반에게 특정 약을 투여했고, 절반에게는 플라시보 효과를 주었다. 1주일 후에 약을 투여받은 사람들 중 12명은 개선 효과가 나타났고 플라시보 그룹에서는 5명이 약효를 보았다. 이 약은 실제로 플라시보 효과보다 효과가 있다고 말할 수 있을까? 그렇다면 얼마나 효과가 있는 것일까? 다르게 얘기하면, 관측되는 비율들의 차이에 기반해보면 (12/50 vs 5/50), 기저에 놓인 어떠한 차이가 실제로 신뢰할만 한 것일까? 이러한 문제들에 조금더 일반적으로 수학적 정교함을 갖추고 이야기를 풀기 위해선, 우리는 몇몇 표기들을 정의할 필요가 있다. 이전 챕터에서 사용했던 몇몇 같은 종류들의 표기를 사용하자. 그룹을 표기할 필요가 있다. 그룹 $"j"$ (j = 1 or j = 2)에서 "heads"의 비율을 $$\theta_j$$로 표기한다. 샘플 $$N_j$$에서 관측되는 실제 heads의 숫자 "flips"를 $$z_j$$로 표기하자. 마지막으로, 그룹 $j$에서 각각의 $i^{th}$ flip은 $$y_{ji}$$로 표기하자. 이번 챕터 전체에서 우리는 두개의 그룹이 서로 독립적이라고 가정할 것이다. 한 그룹의 퍼포먼스가 다른 그룹의 퍼포먼스에 영향을 끼치지 않는다. 일반적으로 우리가 가정한 이 독립성 가정이 들어맞는지에 대하여 우리는 실험을 디자인 한다. 우리가 앞으로 실행할 수학적 분석들에서 독립성은 매우 중요한다. 만약에 우리가 두개의 비율들이 서로 독립적이지 않은 상황에 처한다면, 이번 챕터에서의 방법론은 직접적으로 적용이 힘들 것이다. 데이터간의 의존성이 있는 상황에 대한 이야기는 이번 챕터에서 다루지 않는다.

## 8.1 Prior, likelihood and posterior for two proportions
$\ $ 기저에 놓인 두개의 비율 값들이 있다고 가정해보자($$\theta_1$$,$$\theta_2$$). 우리가 두 그룹에서 몇몇 데이터를 관측한 이후에, 이 값들에 대한 믿음을 결정지으려 한다. 베이지안 통계학에서는, 우리는 해당 데이터가 없을 때에 각각의 비율들에 대한 우리의 사전 믿음을 특정지어야 한다. 이 상황에서, 사전 믿음에 해당하는 확률 $$p(\theta_1, \theta_2)$$는 변수 $$\theta_1$$과 $$\theta_2$$에 의한 함수이다. 우리가 이 함수에 대한 그래프를 그려본다면, 두개 변수에 의한 함수이므로 3차원 형태의 함수가 된다. 또한 해당 함수는 확률밀도함수이므로, 다음이 성립한다. $$\int\int d\theta_1 d\theta_2 p(\theta_1, \theta_2) = 1$$. <br>
$\ $이 챕터의 몇몇 적용 사례에서는, 우리의 $\theta_1$에 대한 사전믿음과, $\theta_2$에 대한 사전믿음이 서로 독립이라고 가정할 것이다. 이런 독립의 경우에 문제는 꽤나 간단해질 수 있다. 그러나 꼭 이 두개의 변수들이 서로 독립이어야만 하는 것은 아니다. 독립이라는 개념 자체에 대해 혼동해서 안되는 것은, 독립이라는 개념이 두 변수 사이의 완벽한 인과관계를 보장하는 것은 아니라는 것이다. 단지, 독립인 두 변수 중 한 변수를 알게 되면, 다른 한 변수에 대한 믿음의 범위를 조금 더 좁힐 수 있다.<br>
$\ $동전 던지기 예시에서, 두 변수간의 독립은 다음과 같이 표현할 수 있다. $$p(y_1|\theta_1,\theta_2) = p(y_2|\theta_1)$$<br>
$ \$한 그룹에서 우리는 데이터 $D_1$를 얻었으며, 총 $$N_1$$의 시도 중에 $$z_1$$번 head를 얻었다. 또 다른 그룹에서 우리는 데이터 $D_2$를 얻었으며, 총 $$N_2$$의 시도 중에 $$z_2$$번 head를 얻었다. 이는 다음과 같이 표현할 수 있다 $$z_1 = \sum_{i=1}^{N_1} y_{1i}$$. 또한, $$z_1 \in \left\{0, ..., N_1\right\}$$ 이며, $$z_2 \in \left\{0, ..., N_2\right\}$$ 이다. 위와 같은 상황을 간단하게 다음과 같이 표현하자. $$D = \left\{z_1, N_1, z_2, N_2\right\}$$. 동전을 던지는 사건들의 독립성을 고려하면 $D$의 확률 값은 각각의 던지는 사건에 대한 베르누이 분포 함수의 곱들로 표현할 수 있다.<br>
!['Img1'](https://imgur.com/OYtItgw.png)
> $$D = \left\{2,5,3,7\right\}$$인 경우에 어떻게 표현하며 계산할지 직접 써보자.

기저에 놓인 비율들의 믿음에 대한 사후 분포는 일반적인 베이즈 규칙을 활용하여 아래와 같이 표현할 수 있다.
!['Img2'](https://imgur.com/J8TaJ47.png)
위의 수식에서, 좌항에 있는 $\theta$ 값들은 특정한 값을 지칭하는 것이지만, 우항의 분모에 있는 적분 내에 있는 $\theta_i$$들은 가능한 모든 $$\theta_i$$ 값에 걸친 것을 지칭하는 것임을 혼동하면 안된다.<br>
$\ $지금까지 살펴본 베이지안 규칙에 의한 두비율에 대한 추론은, 우도 함수가 독립적인 베르누이 분포일 때를 살펴봤다. 특정한 사전 분포에 대해 구체적으로 살펴보자. 형식적인 분석과 grid 근사법을 살펴본 후에 MCMC 근사로 넘어가보자. 특히, 우리는 첫째로 Gibbs 샘플링을 살펴볼 것이다. 마지막 섹션에서 우리는 두 비율간의 차이를 평가하는 데에 집중한다.
# 8.2 The posterior via exact formal analysis
$\ $분석적 방벙을 통해 우리가 베이즈 규칙에 대한 해답을 찾으려 할 때, 어떤 종류의 사전 확률 함수가 해당 추론을 가능하게 할까? 챕터 5에서 우리는 single 비율들에 대한 베르누이 우도 함수에 conjugate한 베타 분포를 배웠기 때문에, 베타 분포라고 답을 할 수도 있을 것이다. 또한, 우리는 베타 분포의 곱들이 베르누이 함수들의 곱과 conjugate할 것이라고 가늠할 수 있다.<br>
$\ $이 것을 간단히 증명할 수 있다. 첫재로, 베타 분포는 다음과 같은 형태를 갖고 있다. $$beta(\theta|a,b) = \theta^{(a-1)} (1-\theta)^{(b-1)}/B(a,b)$$<br>
여기에서 $$B(a,b)$$는 normalizing 항이며, 다음이 성립한다. $$B(a,b) = \int_0^1 d\theta\theta^{(a-1)}(1-\theta)^{(b-1)}$$. $\theta_1$에 대한 사전분포를 $$beta(\theta_1|a_1,b_1)$$, $\theta_2$에 대한 사전분포를 beta(\theta_2|a_2,b_2)$$로 표현한다. 그렇다면 아래와 같은 식을 얻을 수 있다.
!['Img3'](https://imgur.com/gIVdyZJ.png)
수식 (8.3)의 좌항은 확률밀도함수이고, 우항의 분자에 해당하는 부분은 베타분포의 곱이다. 이 수식을 이용해, 베이지안 업데이트가 일어나는 과정은 아래 Figure 8.1에 잘 나타나 있다.<br>
!['Img4'](https://imgur.com/MDIzB01.png)
$\ $위의 그래프는 $\theta_1$, $\theta_2$ 두개의 변수 축에 대한 그림이며, $$p(\theta_1,\theta_2)$$는 해당 값들이 주어졌을 때, 수직 축에 나타나는 값을 알려준다. contour 그래프 또한 참고하며 베이지안 업데이트 상황을 더 잘 이해해보자. 첫 번째 prior는 각각의 비율 값이 0.50 주변에 있을 것이라는 믿음을 보여주며 베타분포 $$beta(\theta|3,3)$$을 이용해서, 표현한다. Figure 8.1의 맨 위 두 그래프를 보면, 0.5 주변에 두 파라미터가 존재하긴 하지만, 뾰족한 peak를 형성하지 못하며 이는 높은 uncertainty가 여전히 존재함을 반영하는 것이다. $\theta_1$ 축에 수직하게 확률밀도함수를 잘라보면 나오게 되는 단면은 $\theta_2$에 의해 변하는 베타 분포의 집합들을 보여준다. 여기서 흥미로운 점은 모든 단면들의 모양이 다 같다는 것이며 모두 $$beta(\theta|3,3)$$으로 표현이 가능하다. 이 상황은 거꾸로 $\theta_2$ 축에 수직하게 자르는 단면을 보아도 마찬가지인데, 이는 두 개의 독립적인 marginal 분포의 곱으로 이뤄진 3차원 그래프라는 것을 반증하는 것이다.<br>
$\ $Contour plot은 각 확률밀도 함수를 바닥과 평행하게 자른 단면들을 보여준다. 결과적으로 사전분포 함수와 우도 함수의 곱으로 사후 분포 함수를 표현해 냈다. 우리가 예전에도 보았지만, 사후 분포는 사전 분포와 우도 함수의 사이에 존재하게 된다. peak point가 어디에 존재하는지 살펴보자.
>지금까지 plot들과 함께 소개된 베타 분포를 포함한 각종 수식은 뒤의 Gibbs sampling 이해에 중요한 역할을 하므로, 잘 숙지할 필요가 있다.

# 8.3 The posterior via grid Approximation
$\ $파라미터 공간이 충분히 작을 때, 우리는 베이즈 룰의 분모에 해당하는 적분 normalizer를 적분이 아닌 sum 값들로 대체할 수 있는 것을 안다. 따라서 아래와 같은 식이 성립한다.
!['Img5'](https://imgur.com/ENupr75.png)
위 식의 첫째 줄에서 $$p(\theta_1,\theta_2)$$는 확률밀도 이지만, 두 번째 줄에서는 확률질량임에 집중해야한다 (이 확률 질량 $$p(\theta_1,\theta_2)$$ 값은 discrete point \theta_1, \theta_2 주변의 작은 범위에서의 값으로 본다). 또한, 좌항에서의 $\theta_1$, $\theta_2$ 값들과 우항에서의 값들은 특정한 값들을 타나내지만, 우항에서 분모의 $\theta_1$, $\theta_2$ 값들은 [0,1] 범위에 존재함을 항상 잊지 말자.<br>
$\ $Grid 근사를 사용하는 것의 큰 장점 중 하나는, 우리가 사후 분포의 특정 형태를 이끌어 내기위해 수학적 분석에 의존할 필요가 없다는 것이다. 그러므로, 우리는 우리가 원하는 어떤 사전분포든지 사용할 수 있고, 여전히 사후분포를 근사시킬 수 있다. Figure 8.2는 수학적으로 풀어내기 어려운 형태의 사전분포를 보여준다. 이 Figure에서 보이는 이러한 사전분포는 실제 연구와 어플리케이션에서 쓰이는 형태는 아니며 단지 가상의 어떠한 사전분포도 사용될 수 있다는 것을 보이기 위함이다.
!['Img6'](https://imgur.com/nJr9doi.png)
