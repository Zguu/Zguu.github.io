---
title: " [Machine Learning] MLE vs MAP"
tags: Machine Learning MLE MAP ParameterEstimation
---

# MLE vs MAP
$ \$ 베이즈 통계학을 공부하면서 항상 궁금증이 명확히 풀리지 않았던 부분을 오늘은 짚고 넘어가자. 일반 통계학에서 다뤘던 MLE 접근과 MAP 사이의 비교를 하며 두 개념을 정리하자.<br>
MLE(Maximum Likelihood Estimation) vs MAP(Maximum A Posterior)<br>

## 1. Maximum Likelihood Estimation
$\ $최대우도추정법으로 번역되는 MLE 접근법에 대해 다시 정리해보자.아직 우리가 정확히 모르는 파라미터 ($\theta$로 표현)를 활용해 표현되는 확률 분포에서,우리가 관측한 데이터 셋 $D$가 출현하게 될 확률을 $$p(D|\theta)$$라고 하자. 식이 말하는 바를 아주 간단히 말하면, 변수가 주어졌을 때 데이터 $D$가 나올 확률. 예를 들어, 동전이 앞면이 나올 사건에 대한 변수 $\theta$가 0.5라면, 그 때 10번의 시행 중 3번이 앞면이 나올 확률은 $${\theta}^3({1-\theta})^7$$이다. 이렇게 특정 파라미터 값이 주어 졌을 때 특정 데이터 셋이 나올 확률을 $$P(D|\theta)$$로 표현한다.<br>
$\ $이렇게 말하는 것이 정확할 지는 모르겠지만(?), 위에서 표현한 $$P(D|\theta)$$ 값은 $\theta$값에 변하는 확률을 보여주므로, 간단히 생각하면 $\theta$ 값을 정의역으로 하는 함수의 일종이라고 볼 수 있다($$f(\theta)$$). 이렇게 $\theta$에 관한 함수라고 생각했을 때, 우리는 이 함수의 최댓값을 어떻게 구할까? 미분을 통해 미분계수가 0이 되도록 하는 $\theta$ 값을 구하면 된다.<br>
$\ $수식을 들이밀면 거부감이 생기기 마련이기 때문에, 결과적으로 MLE의 장단점부터 짚고 넘어가자.
### 장점
- MLE는 파라미터 추정 문제들에 있어서 일관된 해결책을 제시하기 때문에, **다양한 상황** 들에 적용할 수 있다.
- 수학적 계산이 용이하고, 샘플의 크기가 커지면 커질 수록 실제 모집단의 분포를 거의 정확히 표현할 수 있다.
>개인적인 느낌인데.. MLE는 우리가 직관적으로 알고 있는 확률의 기본 개념에 대한 증명이라고 생각한다. 6번을 던져 각 숫자가 나올 확률이 $1/6$인 것에 대한 증명. 하지만, 적용 분야가 방대하고 추가적 확률론의 지식 확장에 주춧돌이 되는 부분이기 때문에 결코 간과할 수는 없는 개념인 듯 하다.

$\ $MLE가 완벽한 방법론이었다면, 우리가 또 다른 어떤 것을 공부 할 필요가 있었겠나. 단점이 있으니 다른 개념들에 대한 필요성이 대두됐을 것이다. 단점들에 대해 살펴보자.
### 단점
- 만약 우리가 파라미터에 대한 신뢰 구간을 얻고 싶은 경우에는, MLE로 문제를 풀어내기가 쉽지 않다.
- *샘플의 수가 매우 작은 경우* 에는, MLE를 통한 결과가 매우 편향적일 가능성이 있다.
> 주사위를 10회 던져 우연치 않게 10번 모두 짝수가 나온다면, 이 주사위는 100% '짝수만' 나온다. 라는 것이 MLE가 우리에게 줄 수 있는 결론이다.

- MLE는 우리가 선택하는 시작 값에 매우 민감하다.
> 위의 주사위 편향의 예시와 연결해서 이해해보자

MLE 수식 표현에 대해 정리하고 MAP로 넘어가자.<br>
<center> $$\hat{\theta_{ML}} = argmax\left\{ Likelihood \right\} = argmax {P(D|\theta)}$$</center>
<center> $$Likelihood\ \ L = \prod_{i=1}^{n} P(y_i | x_i ; \theta)$$</center><br>
## 2. Maximum A Posteriori
$\ $MLE와 MAP의 가장 큰 차이점은, MAP는 **사전정보** 를 활용한다는 것이다. 이렇게 사전정보를 활용하는 MAP의 특성이 MLE에 비해 우월한 결과를 보여주는 경우도 있지만, 반대의 경우도 있다. 아주 당연한 얘기지만, 적절치 못한 사전정보를 MAP에 포함시키게 되면 모델이 생각만큼 좋은 결과를 보여주지는 못한다. 베이즈 규칙에서의 사후확률(Posteriori), 사전확률(Prior), 가능도(Likelihood) 사이의 식은 다음과 같이 표현된다.<br>
<center> $$P(\theta|D) = P(D|\theta)P(\theta)/P(D)$$ </center><br>


$\ $<center> $$\hat{\theta_{MAP}} = argmax\left\{Posteriori\right\} \\= argmax {P(\theta|D)\\= argmax {P(D|\theta)P(\theta)/P(D)} \\= argmax {P(D|\theta)P(\theta)} = argmax\left\{log P(D|\theta) + log P(\theta)\right\}$$</center><br>

MLE : Point Estimation, 점 추정에 해당한다.<br>
parameter1 = (constant[best]) <br>
MAP : Interval Estimation, 구간 추정에 해당한다.<br>
parameter1 = (constant[best]) $$\pm \alpha$$<br>

테스트
