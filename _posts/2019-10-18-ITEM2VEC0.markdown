---
title: " [논문리뷰] ITEM2VEC: Neural Item Embedding for Collaborative Filtering "
tags: PaperReview
---

!['recommendation'](https://scholarshipowl.com/blog/wp-content/uploads/2019/01/72710307_s.png)
# ITEM2VEC: Neural Item Embedding for Collaborative Filtering
### 1. Introduction and related work
<space>

 <center> 아래의 두 개념에 대해 혼동하지 말고 읽으면 더 좋을 것이다<br><br>
 - Item-based Collaborative Filtering<br>
 - User-based Collaborative Filtering<br>
 </center>
<br>
<hr/><br>

 온라인 서비스에서 이제는 우리의 일상이 돼버린 추천 시스템은 자세히 들여다보면 몇가지로 분류를 할 수가 있다. 유저(User)와 아이템(Item) 데이터를 동시 활용하기도 하고, 유저에 대한 정보가 부족하거나 사용이 불가능할 때에 Item(상품이나 서비스)에서 발생하거나 얻을 수 있는 데이터만을 기반으로 한 item-item 추천을 실행하기도 한다. <br>
<space>하지만, 결국에! 소비자에게 아이템을 추천하는 것은 이 item들 간의 유사도를 얼마나 정확하게 계산하느냐의 문제로 볼 수 있다. Single 아이템 추천(유저 정보를 활용하지 않고 아이템 정보만-single item recommendation- 활용한 추천 시스템)은 기존의 전통적인 user-to-item 추천과는 다를 수 있는데, 이것은 유저의 특별한 아이템에 대한 취향 등을 고려하지 않는 외재적(explicit)인 방법으로 볼 수 있다. 이러한 아이템과 아이템 기반의 유사도 측정은 일반적으로 아이템과 유저 기반 유사도보다 CTR(Click-Through Rates: 구매 전환율)이 높기 때문에 더욱 눈 여겨 볼 필요가 있다.<br><br>
<space>물론, 아이템 데이터만 활용해서 추천 시스템을 구축하는 데에 한계가 있는 경우들도 있다. 이 논문의 저자가 말하듯이, 만약 음원 제공 서비스에서 발생하는 케이스에서 처럼, 유저의 수가 압도적으로 아이템의 수보다 많다면(일반적으로 성공한 음원 서비스에서는 이용자의 수가 음원의 수를 훨씬 뛰어 넘는 것과 같이), 유저 베이스 단독 모델로 가는 것이 좋을 수도 있다. 또한, 유저 개개인에 대한 식별이 불가능한 상태에서 (session과 같은), 실제 소비자들의 구매가 이뤄지는 경우도 있다. 이러한 경우에 각각의 Session 단위로 데이터를 취급하고 분석을 진행하는 것은 컴퓨팅 비용 대비 얻을 수 있는 정보가 상대적으로 작기 때문에 유용하지 않다고 한다.<br>
<space>최근(2016년 기준) 자연어 처리 분야에서 큰 진전을 얻게 해준 방법론인 Skip-gram with Negative Sampling(word2vec)에 영감을 받아 진행된 이 연구에서는 최종적으로,<b> ''아이템 데이터를 벡터로 치환하고 유사도 계산을 용이하게 할 수 있다는 것을 이 논문은 보여주려 한다.''</b><br>
<br>


### 2. SGNS

: Mikolov ['(링크)']((https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf))에 의해 제안된 이 방법론은 문장 내에서 단어를 표현하는 데에 있어서, 다른 단어와의 관계에 대한 정보를 캐치한다.

### 3. ITEM2VEC - SGNS FOR ITEM SIMILARITY
:<space> 이제 드디어 본격적으로 논문의 저자가 말하고자 하는 Item2Vec 대해 이야기 해보자! 추천 알고리즘을 구축하는 데에 있어서 우리에게 유저 데이터셋과, 유저가 실제 실행 주문 데이터가 주어지는 게 일반적이다(일반적이라기 보다는 이상적이고 우리는 그래야 행복할 것이다....). 하지만..! 세상은 언제나 우리가 원하는 데이터를 다 예쁘게 포장해서 집 앞까지 배달해주지 않는다. 우리가 원하는 유저와 그에 상응하는 주문 데이터가 없는 경우도 많을 것이다. 주문에 대한 정보는 존재 할지라도, 유저(주문자)에 대한 정보가 경우들이 자주 있다. '어떤 주문이 언제 어디서 이뤄졌고, 배송이 어디로 실행됐는지' 까지는 알아도, 실제로 누가 주문했는지에 대한 식별자 정보(identification)는 여러가지 이유로 부족할 수 있다. (이러한 이유에서 저자는 유저에 대한 임베딩이 아닌, 아이템 임베딩에 더욱 초점을 맞춘게 아닌가 싶다.)<br>
!['anonym'](https://miro.medium.com/max/1360/1*OtVj_gkDk7vuLKYqOZM3qA.jpeg)

이 논문의 저자가 말하기로는, 아이템 기반의 CF(collaborative filtering)에 SGNS 개념을 적용하는 것은 너무나도 직관적이라고 한다. 문장 내에서 단어들이 다른 단어들과의 관계를 갖고 있는 것처럼, 장바구니 내에서 set를 이루는 아이템들도 이러한 맥락에서 이해할 수 있지 않냐는 게 저자의 지적이다. (솔직히 1대1 대응처럼 완벽하게 같은 관계라고 볼 수는 없겠지만, 두 개의 예시가 서로 공유하는 비슷한 특징들이 있다는 건 부인할 수 없어보인다.)<br>
이 연구에서는 여러 개의 아이템들이 만들어 낼 수 있는 시공간적 (spatial/time) 순서는 고려하지 않는다. 단순히 item들의 sets으로만 보고, 시공간에 관련된 정보는 ignore하는 static한 환경으로 본다. 내가 이해한 바로는, 이러한 조건을 둔 덕에, 기존의 SGNS와는 수식이 조금(아주 조금) 달라지게 되는데, 기존의 SGNS는 전 후 C개 만큼의 단어까지 스크리닝을 하며 단어들 간의 관계에 대한 데이터를 활용한 반면, item2vec에서는 각 아이템의 C개 전 후라는 조건을 걸지 않았다. 문장 속의 단어와 장바구니 속의 아이템들 모두 유한한 길이를 갖는 것은 맞지만, 장바구니의 아이템 갯수는 일반적으로 문장 속 단어의 수보다는 적어서 그런 것이 아닐까? 하는 개인적 추측을 해본다. 이렇게 목적 함수 (수식 이미지 추가)에 있어서 미세한 차이 외에는 나머지 과정은 일반적인 SGNS와 모두 같다.

### 4. EXPERIMENTAL SETUP AND RESULTS
:<space> 이 논문의 저자는 item2vec 방법론에 대한 실증적 평가를 보여주기 위해 두 가지 데이터 셋(Microsoft Xbox Music Service 데이터셋과 Microsoft Store에서 상품 주문 데이터셋)을 활용하였고, 양적(quantitative)결과와 질적(qualitative)결과를 모두 보여주고 있다. 비교를 위한 베이스 모델로는 추천 알고리즘에서 가장 많이 사용되는 item-item SVD를 사용했다.<br>
***
 <center><b>논문의 데이터 설명에 대한 직역<br></b><br>
 데이터 셋에 대한 조금 더 구체적인 설명은 다음과 같다.<br>
 Microsoft Xbox Music Service 데이터 셋은 9M events를 포함하고 있으며,각각의 이벤트는 유저와 아티스트 간의 관계로 구성 돼있다 (각 유저는 특정 아티스트의 음악을 재생한 데이터). 이 데이터셋은 732K users 와 49K 의 distinct artists들로 구성 돼있다.<br>
 <b>이 음악 데이터 셋은 장르와 관련한 정보는 제공하고 있지 않는데, 웹으로부터의 장르 메타 데이터를 활용해서 장르-아티스트 카탈로그를 만들었다.</b>이 카탈로그를 활용해서, 우리가 학습한 representations와 장르 간의 관계를 시각화했다.  <br>
 Microsoft Store의 상품 주문에 대한 데이터셋은 주문한 유저의 데이터는 포함하고 있지 않다. 이 데이터 셋은 379K의 주문 수와 1706의 distinct item으로 이뤄져있다.</center>

***

 <space> 웹에서 얻은 정보로 아티스트와 장르를 연결한 경우와, item2vec 기반의 KNN 예측 경우에 후자가 더 좋은 정확도를 보여준다. 특히, 10K unpopular의 경우에 기존의 SVD 정확도에 비해 크게 향상된 정확도를 보여주는데, 이것은 item2vec 과정에서 데이터 간의 불균형을 맞춰주는 subsampling의 효과가 잘 들어맞았던 것으로 보인다 : - 기존 SGNS의 문장 내 단어로 이해를 해보자면, 매우 빈번하게 나오는 단어들의 빈도와 그렇지 않은 (rare)한 단어들의 빈도가 서로 균형이 맞지 않는다. 이러한 불균형(imbalance)을 해결하기 위해 특정 확률 수식을 활용한 subsampling 작업을 진행한다 - <br>
 논문에서 시각화를 위해 사용한 t-SNE embedding에 대한 이해를 위해서는 lovit님의 [(블로그 글)](https://lovit.github.io/nlp/representation/2018/09/28/tsne/)을 확인하면 도움이 될 것이다.<br>

### 5. CONCLUSION

### References
https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf<br>
https://lovit.github.io/nlp/representation/2018/09/28/tsne/<br>
https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c
